{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nibabel","metadata":{"execution":{"iopub.status.busy":"2022-09-13T10:51:29.904032Z","iopub.execute_input":"2022-09-13T10:51:29.905274Z","iopub.status.idle":"2022-09-13T10:51:40.631524Z","shell.execute_reply.started":"2022-09-13T10:51:29.904725Z","shell.execute_reply":"2022-09-13T10:51:40.630198Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\nimport math\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-09-13T10:51:40.636152Z","iopub.execute_input":"2022-09-13T10:51:40.636506Z","iopub.status.idle":"2022-09-13T10:51:45.945368Z","shell.execute_reply.started":"2022-09-13T10:51:40.636471Z","shell.execute_reply":"2022-09-13T10:51:45.944162Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"20 * (math.log(20, 3) ** 2)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T10:51:45.946689Z","iopub.execute_input":"2022-09-13T10:51:45.948989Z","iopub.status.idle":"2022-09-13T10:51:45.961695Z","shell.execute_reply.started":"2022-09-13T10:51:45.948951Z","shell.execute_reply":"2022-09-13T10:51:45.960799Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Download url of normal CT scans.\nurl = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\nfilename = os.path.join(os.getcwd(), \"CT-0.zip\")\nkeras.utils.get_file(filename, url)\n\n# Download url of abnormal CT scans.\nurl = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\nfilename = os.path.join(os.getcwd(), \"CT-23.zip\")\nkeras.utils.get_file(filename, url)\n\n# Make a directory to store the data.\n#os.makedirs(\"MosMedData\")\n\n# Unzip data in the newly created directory.\nwith zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n    z_fp.extractall(\"./MosMedData/\")\n\nwith zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n    z_fp.extractall(\"./MosMedData/\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T10:51:45.962964Z","iopub.execute_input":"2022-09-13T10:51:45.963416Z","iopub.status.idle":"2022-09-13T10:56:21.047515Z","shell.execute_reply.started":"2022-09-13T10:51:45.963379Z","shell.execute_reply":"2022-09-13T10:56:21.046502Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import nibabel as nib\nfrom scipy import ndimage\n\ndef read_nifti_file(filepath):\n    \"\"\"Read and load volume\"\"\"\n    # Read file\n    scan = nib.load(filepath)\n    # Get raw data\n    scan = scan.get_fdata()\n    return scan\n\ndef normalize(volume):\n    \"\"\"Normalize the volume\"\"\"\n    min = -1000\n    max = 400\n    volume[volume < min] = min\n    volume[volume > max] = max\n    volume = (volume - min) / (max - min)\n    volume = volume.astype(\"float32\")\n    return volume\n\ndef resize_volume(img):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = 64\n    desired_width = 128\n    desired_height = 128\n    # Get current depth\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n    # Compute depth factor\n    depth = current_depth / desired_depth\n    width = current_width / desired_width\n    height = current_height / desired_height\n    depth_factor = 1 / depth\n    width_factor = 1 / width\n    height_factor = 1 / height\n    # Rotate\n    img = ndimage.rotate(img, 90, reshape=False)\n    # Resize across z-axis\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img\n\ndef process_scan(path):\n    \"\"\"Read and resize volume\"\"\"\n    # Read scan\n    volume = read_nifti_file(path)\n    # Normalize\n    volume = normalize(volume)\n    # Resize width, height and depth\n    volume = resize_volume(volume)\n    return volume","metadata":{"execution":{"iopub.status.busy":"2022-09-13T10:56:21.050648Z","iopub.execute_input":"2022-09-13T10:56:21.051103Z","iopub.status.idle":"2022-09-13T10:56:22.746276Z","shell.execute_reply.started":"2022-09-13T10:56:21.051065Z","shell.execute_reply":"2022-09-13T10:56:22.744856Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n# no CT-signs of viral pneumonia.\nnormal_scan_paths = [os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n    for x in os.listdir(\"MosMedData/CT-0\")\n]\n# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n# involvement of lung parenchyma.\nabnormal_scan_paths = [\n    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n    for x in os.listdir(\"MosMedData/CT-23\")\n]\n\nprint(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\nprint(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T10:56:22.747527Z","iopub.execute_input":"2022-09-13T10:56:22.748509Z","iopub.status.idle":"2022-09-13T10:56:22.758131Z","shell.execute_reply.started":"2022-09-13T10:56:22.748477Z","shell.execute_reply":"2022-09-13T10:56:22.757111Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Read and process the scans.\n# Each scan is resized across height, width, and depth and rescaled.\nabnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\nnormal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n\n# For the CT scans having presence of viral pneumonia\n# assign 1, for the normal ones assign 0.\nabnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\nnormal_labels = np.array([0 for _ in range(len(normal_scans))])\n\n# Split data in the ratio 70-30 for training and validation.\nx_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\ny_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\nx_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\ny_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\nprint(\n    \"Number of samples in train and validation are %d and %d.\"\n    % (x_train.shape[0], x_val.shape[0])\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T11:11:00.088226Z","iopub.execute_input":"2022-09-13T11:11:00.088601Z","iopub.status.idle":"2022-09-13T11:18:16.452345Z","shell.execute_reply.started":"2022-09-13T11:11:00.088569Z","shell.execute_reply":"2022-09-13T11:18:16.451171Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import random\n\nfrom scipy import ndimage\n\n@tf.function\ndef rotate(volume):\n    \"\"\"Rotate the volume by a few degrees\"\"\"\n\n    def scipy_rotate(volume):\n        # define some rotation angles\n        angles = [-20, -10, -5, 5, 10, 20]\n        # pick angles at random\n        angle = random.choice(angles)\n        # rotate volume\n        volume = ndimage.rotate(volume, angle, reshape=False)\n        volume[volume < 0] = 0\n        volume[volume > 1] = 1\n        return volume\n\n    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n    return augmented_volume\n\ndef train_preprocessing(volume, label):\n    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n    # Rotate volume\n    volume = rotate(volume)\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label\n\ndef validation_preprocessing(volume, label):\n    \"\"\"Process validation data by only adding a channel.\"\"\"\n    volume = tf.expand_dims(volume, axis=3)\n    return volume, label","metadata":{"execution":{"iopub.status.busy":"2022-09-13T11:18:16.454477Z","iopub.execute_input":"2022-09-13T11:18:16.455169Z","iopub.status.idle":"2022-09-13T11:18:16.464222Z","shell.execute_reply.started":"2022-09-13T11:18:16.455130Z","shell.execute_reply":"2022-09-13T11:18:16.463158Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define data loaders.\ntrain_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalidation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n\nbatch_size = 2\n# Augment the on the fly during training.\ntrain_dataset = (\n    train_loader.shuffle(len(x_train))\n    .map(train_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)\n# Only rescale.\nvalidation_dataset = (\n    validation_loader.shuffle(len(x_val))\n    .map(validation_preprocessing)\n    .batch(batch_size)\n    .prefetch(2)\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T11:32:48.925835Z","iopub.execute_input":"2022-09-13T11:32:48.926224Z","iopub.status.idle":"2022-09-13T11:32:53.808537Z","shell.execute_reply.started":"2022-09-13T11:32:48.926191Z","shell.execute_reply":"2022-09-13T11:32:53.807600Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndata = train_dataset.take(1)\nimages, labels = list(data)[0]\nimages = images.numpy()\nimage = images[0]\nprint(\"Dimension of the CT scan is:\", image.shape)\nplt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2022-09-13T11:32:53.810543Z","iopub.execute_input":"2022-09-13T11:32:53.810904Z","iopub.status.idle":"2022-09-13T11:32:55.299794Z","shell.execute_reply.started":"2022-09-13T11:32:53.810859Z","shell.execute_reply":"2022-09-13T11:32:55.298906Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def plot_slices(num_rows, num_columns, width, height, data):\n    \"\"\"Plot a montage of 20 CT slices\"\"\"\n    data = np.rot90(np.array(data))\n    data = np.transpose(data)\n    data = np.reshape(data, (num_rows, num_columns, width, height))\n    rows_data, columns_data = data.shape[0], data.shape[1]\n    heights = [slc[0].shape[0] for slc in data]\n    widths = [slc.shape[1] for slc in data[0]]\n    fig_width = 12.0\n    fig_height = fig_width * sum(heights) / sum(widths)\n    f, axarr = plt.subplots(\n        rows_data,\n        columns_data,\n        figsize=(fig_width, fig_height),\n        gridspec_kw={\"height_ratios\": heights},\n    )\n    for i in range(rows_data):\n        for j in range(columns_data):\n            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n            axarr[i, j].axis(\"off\")\n    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n    plt.show()\n\n\n# Visualize montage of slices.\n# 4 rows and 10 columns for 100 slices of the CT scan.\nplot_slices(4, 10, 128, 128, image[:, :, :40])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T11:32:55.301063Z","iopub.execute_input":"2022-09-13T11:32:55.301722Z","iopub.status.idle":"2022-09-13T11:32:56.638814Z","shell.execute_reply.started":"2022-09-13T11:32:55.301684Z","shell.execute_reply":"2022-09-13T11:32:56.634565Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_model(width=128, height=128, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    \n    x = layers.Conv3D(filters=64, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=128, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=512, activation=\"relu\")(x)\n    x = layers.Dropout(0.2)(x)\n    \n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n    return model\n\n\n# Build model.\nmodel = get_model(width=128, height=128, depth=64)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-13T12:48:37.920903Z","iopub.execute_input":"2022-09-13T12:48:37.921282Z","iopub.status.idle":"2022-09-13T12:48:38.044754Z","shell.execute_reply.started":"2022-09-13T12:48:37.921249Z","shell.execute_reply":"2022-09-13T12:48:38.043684Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Compile model.\ninitial_learning_rate = 0.0001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, \n                                                          decay_steps=100000, \n                                                          decay_rate=0.96, \n                                                          staircase=True)\nmodel.compile(loss=\"binary_crossentropy\",\n              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n              metrics=[\"acc\"],)\n\n# Define callbacks.\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"3d_image_classification.h5\", save_best_only=True)\nearly_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n\n# Train the model, doing validation at the end of each epoch\nepochs = 100\nmodel.fit(train_dataset,validation_data=validation_dataset,epochs=epochs,shuffle=True,verbose=1,\n          callbacks=[checkpoint_cb],)","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-09-13T12:48:47.562809Z","iopub.execute_input":"2022-09-13T12:48:47.563195Z","iopub.status.idle":"2022-09-13T13:45:08.166397Z","shell.execute_reply.started":"2022-09-13T12:48:47.563151Z","shell.execute_reply":"2022-09-13T13:45:08.165419Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"loss\"]):\n    ax[i].plot(model.history.history[metric])\n    ax[i].plot(model.history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-13T13:53:35.603240Z","iopub.execute_input":"2022-09-13T13:53:35.603617Z","iopub.status.idle":"2022-09-13T13:53:35.994497Z","shell.execute_reply.started":"2022-09-13T13:53:35.603586Z","shell.execute_reply":"2022-09-13T13:53:35.993456Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Load best weights.\nmodel.load_weights(\"3d_image_classification.h5\")\nprediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\nscores = [1 - prediction[0], prediction[0]]\n\nclass_names = [\"normal\", \"abnormal\"]\nfor score, name in zip(scores, class_names):\n    print(\n        \"This model is %.2f percent confident that CT scan is %s\"\n        % ((100 * score), name)\n    )","metadata":{"execution":{"iopub.status.busy":"2022-09-13T13:53:37.995484Z","iopub.execute_input":"2022-09-13T13:53:37.996602Z","iopub.status.idle":"2022-09-13T13:53:38.242062Z","shell.execute_reply.started":"2022-09-13T13:53:37.996557Z","shell.execute_reply":"2022-09-13T13:53:38.240862Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}